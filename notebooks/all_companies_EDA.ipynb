{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/roshansharma/amazon-alexa-reviews\n",
    "\n",
    "# Disclaimer\n",
    "# I don't have any connection with Glassdoor and this \n",
    "# project is neither approved or endorsed by them. \n",
    "# The data collected, and made available here was publicly accessible \n",
    "# (without even logging in to the website) at the moment it was collected.\n",
    "# This dataset was created for educational purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# libraries for visualization\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "# For latent dirichlet allocation\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# For modelling and ELI5 analysis\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import eli5\n",
    "\n",
    "# Set width of notebook\n",
    "from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:60% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "os.chdir('/Users/hectortemp/github/pytrust')\n",
    "# Used for plotting visualisations\n",
    "from pytrust.examine.plotting_trust import *\n",
    "\n",
    "# Used for cleaning (lemmatizing, removing punctuation, lower case etc...)\n",
    "from pytrust.examine.clean_words import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: find all csvs in data folder\n",
    "import glob, os\n",
    "list_of_csvs = glob.glob(\"data/*.csv\")\n",
    "comp_names = [i.replace('www_', '').split('_')[1] for i in list_of_csvs]\n",
    "# Read them all in\n",
    "\n",
    "\n",
    "data = pd.DataFrame()\n",
    "for comp, path in zip(comp_names, list_of_csvs):\n",
    "    df_hold = pd.read_csv(path)\n",
    "    df_hold.insert(0, 'company', comp)\n",
    "    data = pd.concat([data, df_hold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfs                45137\n",
       "amazon             14612\n",
       "ubereats           12732\n",
       "ocado              11274\n",
       "just-eat            7427\n",
       "deliveroo           7040\n",
       "asda                6259\n",
       "tesco               5886\n",
       "sainsburys          4243\n",
       "morrisons           3593\n",
       "marksandspencer     3186\n",
       "aldi                2457\n",
       "iceland             2359\n",
       "waitrose            1876\n",
       "lidl                1510\n",
       "co-operative         558\n",
       "farmfoods            160\n",
       "booths                20\n",
       "Name: company, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['company'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 2: clean data\n",
    "data = clean_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3a: How do we know which words to remove\n",
    "a = [item for sublist in data['content_clean'].str.split().values for item in sublist]\n",
    "pd.Series(a).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3b: remove custom stopwords\n",
    "custom_stopwords = comp_names\n",
    "data = remove_custom_stopwords(df = data,\n",
    "                        custom_stop = custom_stopwords,\n",
    "                        cols = ['title_clean', 'content_clean'])\n",
    "# Step 4: replace content and title with the clean versions\n",
    "REPLACE = True\n",
    "if REPLACE:\n",
    "    data['title'] = data['title_clean']\n",
    "    data['content'] = data['content_clean']\n",
    "    data = data.drop(['title_clean', 'content_clean'], axis = 1)\n",
    "    \n",
    "# Step 5: Create quantitative features\n",
    "data = create_fea(data)\n",
    "\n",
    "# Step 6: Fix spelling - not yet implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today().strftime('%Y_%m_%d')\n",
    "data.to_csv(f'clean_data/{today}_FULL_clean.csv')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Oldest review:\", data['date'].min(), \", Newest review:\", data['date'].max())\n",
    "\n",
    "top_pct_to_drop = 0.02\n",
    "data = data.sort_values('content_num_words', ascending=False).iloc[round(data.shape[0] * top_pct_to_drop):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also remove reviews with no content\n",
    "print(data.shape)\n",
    "data = data[(data['content'].str.len() != 0) & (data['content'].str.len() != 1)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pie_chart(df = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_star_funnel(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dist3(data[data['num_stars'] == 5], 'content_num_char',\n",
    "       'Characters Per \"Positive review')\n",
    "plot_dist3(data[data['num_stars'] == 1], 'content_num_char',\n",
    "       'Characters Per \"Negative review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_len_histogram(data[data['num_stars'] == 5]['content'],\n",
    "                       data[data['num_stars'] == 1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dist3(data[data['num_stars'] == 5], 'content_num_words',\n",
    "       'Words Per \"Positive review')\n",
    "plot_dist3(data[data['num_stars'] == 1], 'content_num_words',\n",
    "       'Words Per \"Negative review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale = 2)\n",
    "g = sns.FacetGrid(data, col='num_stars', height=4)\n",
    "g.map(plt.hist,'content_num_char')\n",
    "plt.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle(f'Size of review distribution, by number of stars')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams(df = data, n = 1, title = 'Most Common Unigrams', mx_df = 0.9, content_or_title = 'content')\n",
    "ngrams(df = data, n = 1, title = 'Most Common Unigrams', mx_df = 0.9, content_or_title = 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams(df = data, n = 2, title = 'Most Common Bigrams', mx_df = 0.9, content_or_title = 'content')\n",
    "ngrams(df = data, n = 2, title = 'Most Common Bigrams', mx_df = 0.9, content_or_title = 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams(df = data, n = 3, title = 'Most Common Trigrams', mx_df = 0.9, content_or_title = 'content')\n",
    "ngrams(df = data, n = 3, title = 'Most Common Trigrams', mx_df = 0.9, content_or_title = 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting_trust import display_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Topics for TITLE of review')\n",
    "display_topics(data[data['num_stars'] == 5]['title'], \n",
    "               no_top_words = 5,\n",
    "               topic = 'Positive review topics \\n',\n",
    "               components = 10)\n",
    "print('\\n======================================\\n')\n",
    "print('\\n======================================\\n')\n",
    "print('Topics for BODY of review')\n",
    "display_topics(data[data['num_stars'] == 5]['content'], \n",
    "               no_top_words = 5,\n",
    "               topic = 'Positive review topics \\n',\n",
    "               components = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Topics for TITLE of review')\n",
    "display_topics(data[data['num_stars'] == 1]['title'], \n",
    "               no_top_words = 5,\n",
    "               topic = 'Negative review topics \\n',\n",
    "               components = 10)\n",
    "print('\\n======================================\\n')\n",
    "print('\\n======================================\\n')\n",
    "print('Topics for BODY of review')\n",
    "display_topics(data[data['num_stars'] == 1]['content'], \n",
    "               no_top_words = 5,\n",
    "               topic = 'Negative review topics \\n',\n",
    "               components = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_slider(df = data, window = 30, add_count = False, add_var = True, add_kurt = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data\n",
    "data_for_reg = data[data['num_stars'] != 3].copy()\n",
    "data_for_reg.loc[:,'target'] = -9999\n",
    "data_for_reg.loc[data_for_reg['num_stars'] < 3, 'target'] = 0 #Â 0 negative\n",
    "data_for_reg.loc[data_for_reg['num_stars'] > 3, 'target'] = 1 # 1 positive\n",
    "\n",
    "X_full = data_for_reg['content']\n",
    "y_full = data_for_reg['target']\n",
    "\n",
    "vect = TfidfVectorizer()\n",
    "X = vect.fit_transform(X_full)\n",
    "\n",
    "y = y_full\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=23, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Train Set Accuracy: {}\".format(metrics.accuracy_score(model.predict(X_train), y_train)))\n",
    "print(\"Train Set ROC: {}\\n\".format(metrics.roc_auc_score(model.predict(X_train), y_train)))\n",
    "\n",
    "print(\"Validation Set Accuracy: {}\".format(metrics.accuracy_score(model.predict(X_valid), y_valid)))\n",
    "print(\"Validation Set ROC: {}\".format(metrics.roc_auc_score(model.predict(X_valid), y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(model.predict(X_valid), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\\\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "axes = axes.flatten()\n",
    "sns.set(font_scale=2.0)\n",
    "for norm, j in zip(['true', None], axes):\n",
    "    plot_confusion_matrix(model, X_valid, y_valid, normalize = norm, ax = j)\n",
    "axes[0].set_title(f'Normalised confusion matrix', fontsize = 24)\n",
    "axes[1].set_title(f'Raw confusion matrix', fontsize = 24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [0, 1]\n",
    "eli5.show_weights(model, vec=vect, top=100,\n",
    "                  target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
